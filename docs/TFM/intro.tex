\section{Introduction}
Neural rendering methods such as NeRF models and their variations \cite{mildenhall2020nerf, barron2021mipnerf, barron2022mipnerf360, garbin2021fastnerf} are a significant step forward in the field of photorealistic novel-view synthesis of scenes reconstructed from a series of photos. While they provide very good results and their structure is better suited for optimization compared to primitive-based rendering methods, they are slow to evaluate, which limits their use in real-time rendering applications. 3D Gaussian Splatting \cite{kerbl3Dgaussians} comes as an alternative to these neural methods. It combines the fast rendering capabilities of primitive-based representations with a differentiable tile renderer. This allows for state-of-the-art image quality while keeping training times low and making this solution viable for real-time rendering. 

While this Gaussian-based representation significantly increases the performance of novel-view synthesis methods, it still requires high amounts of processing power which is usually not readily available in consumer products. This is in most part caused by the density of primitives in 3DGS models, as the optimization algorithm introduces more Gaussians in order to better represent fine features. While this provides superior image quality, it limits the achievable rendering performance on lower-powered devices. Several publications investigated multiple ways of reducing the primitive count of 3DGS models, some using a more aggressive pruning approach during optimization \cite{fan2023lightgaussian}, while others generating multiple scene representations with decreasing detail \cite{kerbl_hierarchy, liu2024citygaussian, ren2024octreegs}, and combining them during rendering. What all of these implementations have in common is that the representations with fewer primitives are always introduced to the optimization loop for a significant amount of steps, and are optimized alongside the whole scene. This means that more time, powerful hardware, and the original reference images are necessary to create a lower-detail representation of the scene, which is not guaranteed that it can be done on the consumer side.

In this project, I will present the approach I took to accelerating 3DGS rendering using a hierarchical Level of Detail structure which can select the appropriate detail level for different parts of the scene. This is an adaptation of the LoD used in traditional triangle graphics, where multiple versions of the mesh are stored and replaced in rendering depending on the available resources and distance to the camera in order to maintain the desirable framerate. This implementation differs from traditional LoDs in the sense that the detail level can vary throughout the scene, so there is a need for additional spatial partitioning and ensuring the transitions between adjacent levels do not introduce significant visual artifacts. This system will allow for lower-detail representations of a model to be generated without additional optimization steps and introduces the detail selection to the rendering loop with minimal changes to the current pipeline, and without changing the model representation. 